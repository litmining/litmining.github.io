
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Set of tools and workflow for easy and efficient text-mining of the biomedical scientific literature." />
    <title>Mining the biomedical scientific literature</title>
    <link rel="stylesheet" href="/css/global.css?63320c2136d2b95b" />
</head>

<body>
    <main>
            <header class="wrapper header">
                <h1>Mining the biomedical scientific literature</h1>
                <p>
                    We present a set of tools and resources to easily collect and prepare data for text-mining the bio­medical scientific literature. Skip the tedious data collection and wrangling and focus on information extraction and analysis!
                </p>
            </header>
            <article class="wrapper region">
                <p>The biomedical literature comprises millions of articles and is expanding quickly.
Due to this overwhelming size, using it efficiently often involves systematic or automated methods, collectively known as <em>text-mining</em>.
A text-mining project involves several steps: finding relevant articles, downloading them, extracting their text, extracting information from the text and finally running the main analysis which yields scientific insights.
More often than not, the first steps of this process – data collection and curation – take a frustrating amount of time and effort, and are performed in a way that is difficult to reproduce or extend later.</p>
<p>Here, we describe useful tools and a simple workflow that make text-mining of the biomedical literature easier, more transparent and more fun.
We hope to help you streamline the first tedious steps of your text-mining project and focus on the part you care about: extracting and analyzing high-quality information from text, rather than downloading, parsing and pre-processing thousands of articles.</p>
<p>Here is an overview of our suggested workflow, along with the tools we offer and possible places to store the output of each step.</p>
<div class="workflow-figure">
    <div class="workflow-header">
        Task
    </div>
    <div class="workflow-header">
        Tool
    </div>
    <div class="workflow-header">
        Output
    </div>
    <div class="step">
        Corpus collection & content extraction
    </div>
    <div class="tool">
        <a href="https://neuroquery.github.io/pubget/">pubget</a>
    </div>
    <div class="location">
        <a href="https://osf.io/d2qbh/">OSF</a>
    </div>
    <div class="workflow-arrow"><img alt="↓" src="/images/arrow.svg" width="32" height="32"></div>
    <div class="workflow-empty"></div>
    <div class="workflow-empty"></div>
    <div class="step manual-annotation">
        Manual annotation
    </div>
    <div class="tool manual-annotation">
        <a href="https://jeromedockes.github.io/labelbuddy/">labelbuddy</a>
    </div>
    <div class="location manual-annotation">
        <a href="https://litmining.github.io/labelbuddy-annotations/">labelbuddy-annotations</a>
    </div>
    <div class="workflow-sides step and-or">
        <fieldset>
            <legend>and/or</legend>
        </fieldset>
    </div>
    <div class="border-bottom tool"></div>
    <div class="border-bottom location"></div>
    <div class="workflow-sides tool"></div>
    <div class="workflow-sides location"></div>
    <div class="step automatic-extraction workflow-task">
        Automatic information extraction
    </div>
    <div class="tool automatic-extraction">
        <a href="https://neuroquery.github.io/pubget/">pubget</a>,
        <a href="https://github.com/neurodatascience/pubextract/">pubextract</a>,
        custom code
    </div>
    <div class="location automatic-extraction">
        GitHub
    </div>
    <div class="workflow-arrow"><img alt="↓" src="/images/arrow.svg" width="32" height="32"></div>
    <div class="workflow-empty"></div>
    <div class="workflow-empty"></div>
    <div class="step">
        Analysis
    </div>
    <div class="tool">
        Custom code
    </div>
    <div class="location">
        GitHub
    </div>
</div>
<ul>
<li>Our tool <a href="https://neuroquery.github.io/pubget/">pubget</a> performs the tasks of collecting documents and extracting their content.</li>
<li>The corpora created by pubget can be stored in a dedicated <a href="https://osf.io/d2qbh/">OSF project</a>.</li>
<li>Our tool <a href="https://jeromedockes.github.io/labelbuddy/">labelbuddy</a> can be used to manually annotate papers.</li>
<li>We have an open repository of <a href="https://litmining.github.io/labelbuddy-annotations/">labelbuddy annotations</a>, where researchers can re-use, update, and add new annotations.</li>
<li>Our tools <a href="https://neuroquery.github.io/pubget/">pubget</a> and <a href="https://github.com/neurodatascience/pubextract/">pubextract</a> can be used to automatically extract information.</li>
<li>For the step of analyzing the data, each project can have its own code (“custom code”), which we hope would be tracked and shared in its own repository on GitHub or elsewhere (“GitHub repo”).</li>
</ul>
<h2>Pubget</h2>
<p>Pubget is a command-line program to obtain and process full-text articles from <a href="https://www.ncbi.nlm.nih.gov/pmc/">PubMed Central</a> (PMC).
For example, here is how we would obtain all the articles that mention “zika” in their abstract:</p>
<pre><code>pubget run -q &quot;zika[Abstract]&quot; ./pubget_data
</code></pre>
<p>The pubget <a href="https://neuroquery.github.io/pubget/">documentation</a> provides a detailed description of all the options and outputs, and <code>pubget --help</code> produces a summary.
After downloading all the articles, pubget extracts their content, including the text, abstract, metadata fields such as keywords and publication date, etc.
This data is stored in CSV files that are easily loaded to analyze all the articles jointly.</p>
<p>pubget also has some features specific to meta-analysis of neuroimaging studies, such as the extraction of stereotactic coordinates.
For more details, see the documentation!</p>
<h2>Labelbuddy</h2>
<p>In a text-mining project, we often need some manual annotations.
For example, if we create a method for automatically extracting information from the text, we need labelled documents at least for validation (evaluating how well the automatic extraction performs).<br>
<a href="https://jeromedockes.github.io/labelbuddy/">Labelbuddy</a> is a simple, effective and flexible tool for performing this task.</p>
<p>Conveniently, pubget can generate JSON files containing the text it downloaded, simply by adding the <code>--labelbuddy</code> flag to the pubget command.
Therefore, we can start annotating our articles very easily:</p>
<pre><code>pubget run -q &quot;zika[Abstract]&quot; \
           --labelbuddy        \
           --alias zika_papers \
           ./pubget_data

cd ./pubget_data/zika_papers/subset_allArticles_labelbuddyData/

labelbuddy ./zika.labelbuddy --import-docs documents_00001.jsonl
labelbuddy ./zika.labelbuddy
</code></pre>
<p>The <code>--alias zika_papers</code> tells pubget to create a symlink with a human-readable name for the directory in which it stores its output.
The last 2 commands, which import the papers into a labelbuddy database and then open it in the application, can also be performed from labelbuddy’s graphical interface instead of the command-line.
For more details about labelbuddy, see its <a href="https://jeromedockes.github.io/labelbuddy/labelbuddy/current/documentation/">documentation</a>.</p>
<h2>The labelbuddy-annotations repository</h2>
<p>This is completely optional, but if you annotate biomedical text with labelbuddy, we encourage you to share the annotations in this <a href="https://litmining.github.io/labelbuddy-annotations/">repository</a>.
This will facilitate re-use of annotations in different analyses, and collaboration across projects (eg different projects annotating the same articles with different types of information).
As a bonus, you get a few utilities to work with the annotations, and yo can showcase your project in the repository’s documentation.</p>
<h2>Workflow</h2>
<p>Data collection, labelling and cleaning tend to be messy.
Still, we want the process to be as streamlined, transparent and reproducible as possible.
Here is an overview of the organization we suggest; more technical details are provided in the labelbuddy-annotations repository’s <a href="https://litmining.github.io/labelbuddy-annotations/contributing_to_this_repository.html">documentation</a>.</p>
<h3>Visit <a href="https://www.ncbi.nlm.nih.gov/pmc/">PubMed Central</a> to select a query</h3>
<h3>Download &amp; process articles with pubget</h3>
<h3>Store the full pubget output on <a href="https://osf.io/d2qbh/">OSF</a></h3>
<h3>Add a project to the labelbuddy-annotations repository</h3>
<h3>Use your text corpus and manual annotations for analysis</h3>
<h3>Distribute your code &amp; analysis</h3>

            </article>
    </main>
</body>

</html>
